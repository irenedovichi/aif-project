{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minihack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minihack env creation with a .des file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"MiniHack-Navigation-Custom-v0\",\n",
    "    observation_keys=(\"chars\", \"pixel\"),\n",
    "    des_file = \"maps/complex_maze.des\",\n",
    "    max_episode_steps=10000,\n",
    ")\n",
    "state = env.reset()\n",
    "#env.render()\n",
    "plt.imshow(state['pixel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "game_map = state['chars']\n",
    "game = state['pixel']\n",
    "start = get_player_location(game_map)\n",
    "target = get_target_location(game_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"> start: {start}, target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have to decide if we want to generate a random path or random actions\n",
    "\n",
    "random path $\\Rightarrow$ a path of exactly n steps\n",
    "\n",
    "random actions $\\Rightarrow$ many action will be not valid $\\Rightarrow$ the path will be shorter OR, as is implemented now, with many repetition of the same position.\n",
    "\n",
    "# NOTE:\n",
    "minihack wont crash if we input a not valid action starting from a valid action. It will simply not execute the action (as if we are playing), hence we are updating the path position with the same position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_nsteps(game_map, start, target) # RANDOM VALID PATH\n",
    "#random_nactions()                      # RANDOM (TO CHECK VALIDITY) ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MAX_GENERATIONS = 1000\n",
    "MAX_INDIVIDUALS = 100\n",
    "\n",
    "best_scores =[]\n",
    "best_paths = []\n",
    "zero_fitness = []\n",
    "\n",
    "# create a list of individuals, starting with random moves (illegal actions filtered out)\n",
    "print(\"> Creating initial population...\")\n",
    "individuals = [true_random_nsteps(game_map, start, target) for _ in range(MAX_INDIVIDUALS)]\n",
    "best_fitness = np.inf\n",
    "\n",
    "print(\"> Evolving...\")\n",
    "for generation in tqdm(range(MAX_GENERATIONS)):\n",
    "    \n",
    "    generation_scores = []\n",
    "\n",
    "    fitnesses = [fitness_function(individual, checkpoints, generation) for individual in individuals]\n",
    "    #fitness_function = lambda path: abs(path[-1][0] - target[0]) + abs(path[-1][1] - target[1])\n",
    "\n",
    "    ind_actions = [actions_from_path(start, ind) for ind in individuals]\n",
    "    generation_scores.append(min(fitnesses))\n",
    "\n",
    "    # this is a list of tuples (individual, fitness). individual is a list of moves\n",
    "    population = list(zip(individuals, fitnesses))\n",
    "    actions =  list(zip(ind_actions, fitnesses))\n",
    "\n",
    "    # sorting the population by best fitness (lower is better)\n",
    "    population.sort(key=lambda x: x[1])\n",
    "    actions.sort(key=lambda x:x[1])\n",
    "    # sort ind_actions with respect to population\n",
    "    \n",
    "    #print(f\"best score: {population[0][1]:.2f}\")\n",
    "\n",
    "    # take 2 best individuals -> maybe can be replaced with probability distribution based on fitness\n",
    "    # also roulette wheel selection.\n",
    "\n",
    "    child1, child2, = actions[0][0], actions[1][0]\n",
    "\n",
    "    offspring = [crossover(child1, child2) for _ in range(MAX_INDIVIDUALS)]\n",
    "    offspring = [mutate(child) for child in offspring]\n",
    "    ind_actions = offspring\n",
    "    individuals = [path_from_actions(game_map, start, child) for child in offspring]\n",
    "\n",
    "    best_fitness = population[0][1]\n",
    "    best_scores.append(population[0][1])    \n",
    "    best_paths.append(population[0][0])\n",
    "    #print(f\"Generation {generation}: best score {best_fitness:.2f}\")\n",
    "\n",
    "    if best_fitness == 0:\n",
    "        zero_fitness.append(population[0][0])\n",
    "    \n",
    "# print best score and best path\n",
    "best_idx = np.argmin(best_scores)\n",
    "print(f\"Best score: {best_scores[best_idx]:.2f}\")\n",
    "print(f\"Best path: {best_paths[best_idx]}\")\n",
    "print(f\"generation of best path: {best_idx}\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
